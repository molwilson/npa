---
title: "NPA long-term reef monitoring"
author: "Molly Wilson"
date: "7/20/2022"
output: 
  html_document:
    code_folding: hide
---
# {.tabset}

```{r, message = F, warning = F, echo = F}
library(tidyverse)
library(here) 
# library(readxl) 
library(janitor)
library(snakecase) # for adjusting capitalization of text within data (e.g., species names)
library(knitr) # for including tables
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

```{r}
raw_fish <- read.csv(here("reef monitoring", "data", "fish.csv"), header = FALSE) %>%  
  clean_names()

fish <- tibble(surveyor = raw_fish[1,2], date = raw_fish[1,8], site = raw_fish[1,5], 
                   transect = raw_fish[2,2], depth_start = raw_fish[3,3], depth_end = raw_fish[3,5], 
                   temp = raw_fish[3,7]) %>%
  cbind(raw_fish %>% # binding with reformatted fish data
    filter(row_number() %in% 5:19) %>% # selecting rows that have size bin data
    select(-v2) %>% # random blank column
    row_to_names(1) %>%
    clean_names() %>%
    mutate_all(funs(replace(., .=="", 0))) %>% # replace all empty cells with 0
    pivot_longer(!fish_groups, names_to = "size_bin", values_to = "count") %>%
    mutate_at("size_bin", str_replace, "x", "") %>%
    rbind(raw_fish %>% # adding other rows with no size bin data
      filter(row_number() %in% 20:23) %>%
      mutate_all(funs(replace(., .=="", 0))) %>%
      mutate(count = rowSums(across(where(is.numeric)))) %>%
      select(fish_groups = v1, count) %>%
      mutate(size_bin = "NA")
  ))

```

Question at this point is.... how are we going to process large amounts of inputted data?

